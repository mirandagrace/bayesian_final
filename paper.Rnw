\documentclass{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx,float}
\usepackage{multirow,setspace}
\usepackage{enumerate}
\usepackage{booktabs}
\usepackage{placeins}
\usepackage{cite}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{listings}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\tab}{\hspace{0.5cm}}
\newcommand{\modref}[1]{(\ref{#1})}
\mathchardef\mhyphen="2D




\newcounter{DefnCounter}
\setcounter{DefnCounter}{1}

\newcounter{ThmCounter}
\setcounter{ThmCounter}{1}

\newcounter{ExampleCounter}
\setcounter{ExampleCounter}{1}

\newcommand{\defn}[1]{\textsc{Definition 1.\arabic{DefnCounter}\stepcounter{DefnCounter}: #1\\} }
\newcommand{\thm}{\textsc{Theorem 1.\arabic{ThmCounter}\stepcounter{ThmCounter}\\} }
\newcommand{\ex}{\textsc{Example 1.\arabic{ExampleCounter}\stepcounter{ExampleCounter}\\} }

\newcommand{\Defn}{\underline{Definition}}
\newcommand{\Q}{\underline{Question}}
\newcommand{\Qs}{\underline{Questions}}
\newcommand{\bbeta}{{\mbox{\boldmath$\beta$}}}
\newcommand{\bmu}{{\mbox{\boldmath$\mu$}}}
\newcommand{\balpha}{{\mbox{\boldmath$\alpha$}}}
\newcommand{\btheta}{{\mbox{\boldmath$\theta$}}}
\newcommand{\bphi}{{\mbox{\boldmath$\phi$}}}
\newcommand{\bSigma}{{\mbox{\boldmath$\Sigma$}}}
\newcommand{\bLambda}{{\mbox{\boldmath$\Lambda$}}}
\newcommand{\bpi}{{\mbox{\boldmath$\pi$}}}
\newcommand{\R}{\texttt{R}}
\newcommand{\Lik}{\mathcal{L}}
\newcommand{\bx}{\textbf{x}}
\newcommand{\by}{\textbf{y}}
\newcommand{\bX}{\textbf{X}}
\newcommand{\sic}{\text{Inv-}\chi^2}


\newcommand{\sao}{SaO$_2$}

\setlength{\marginparwidth}{2cm}
\begin{document}
<<imports, cache=FALSE, echo=FALSE>>= 
read_chunk('zinb_sampler.R')
options(scipen=4, digits=3)
library('truncnorm')
@
<<dataset, echo=FALSE, cache=FALSE>>= 
load('small_storms.RData')
storm_details <- small_storms
@
\begin{center}
	\vspace{0.1cm}
	\textsc{\LARGE MATH 640 Final Project} \\[0.1cm]
	Jason Michaels (jam521), Niko Paulson (ndp32), Miranda Seitz-McLeese (mgs85) 
\end{center}
\section{Introduction}
\label{s:intro}
This analysis will be done on a data set of a variety of measurements about severe weather in the United States. 
The data set contains a variety of measures from severe weather events in the United States from 1996-2016. It was taken from the NOAA website \cite{dataset}.
For this project we focused on the deaths directly attributable to the event.
Understanding how and at what rate severe weather events become lethal in the United States has tremendous public health impacts.
In this paper we compare four possible models for the deaths: The traditional Poisson and negative binomial distributions, as well as the zero inflated variant of each.

The remainder of this analysis is organized as follows: Section~\ref{s:methods} discusses and derives the models. Section~\ref{s:results} describes the results of the analysis. And Section~\ref{s:discussion} contains the conclusions.

\section{Methods}
\label{s:methods}
The deaths attributed to a severe weather event is `count' data. 
The most common model used for count data is the Poisson distribution. 
However for some weather events, the negative binomial model is a better fit, because the Poisson distribution assumes that the events being counted occur independently.

Fortunately, the vast majority of severe weather events in the United States involve no deaths, therefore we wanted to also account for the possibility of structural zeros, therefore we also considered zero inflated variants. 
These distributions are created by returning $0$ with probability $\sigma$ and sampling from the original distribution with probability $(1-\sigma)$. 

We will derive and fit a model for each of the four distributions and see if there is a difference in our results and evaluate to determine which model best fits the data.

\subsection{Poisson}
\label{ss:mPoisson}
The Poisson model has one parameter, $\lambda$ represents the expected number of occurances of the event of interest. For a single random variable $x$, the probability density is:
$$p(x|\lambda)=\frac{\lambda^xe^{-\lambda}}{x!}.$$
Thus the likelihood for a sum of Poisson random variables can be written as follows:
$$\mathcal{L}(X|\lambda)\propto\lambda^{n\bar{X}}e^{-n\lambda}.$$ 
Since we want the data to speak for itself, we will use a non-informative random variable, namely, Jeffreys' prior. For the Poisson distribtion this is given as follows:
$$\pi(\lambda)\propto\lambda^{1/2-1}e^{-0\cdot\lambda}.$$
We recognize this as the kernel of an improper gamma distribution. Combining the likelihood and the prior distribtion yields the following posterior distribution:
$$p(\lambda|X)=\lambda^{n\bar{X}+1/2-1}e^{-n\lambda}.$$
We recognize this as the kernel of a gamma distribution, namely
$$\lambda|X\sim\mathcal{G}amma(n\bar{X}+1/2,n).$$

\subsection{Negative Binomial}
\label{ss:mNBinom}
The Negative Binomial model has two parameters, $r,p$ represents the expected number of occurances of the event of interest. For a single random variable $x$, the probability density is:
$$p(X|r,p)=\frac{\Gamma(r+x)}{\Gamma(r)x!}p^{x}(1-p)^{r}.$$

Thus the likelihood for a sum of Negative Binomial random variables can be written as follows:
$$\mathcal{L}(X|r,p)=\Bigg[\prod_{i=1}^n\frac{\Gamma(r+x_i)}{\Gamma(r)x_i!}\Bigg]p^{n\bar{X}}(1-p)^{nr}.$$
Since we want the data to speak for itself, we will use a non-informative random variable, namely, Jeffreys' prior. For the Poisson distribtion this is given as follows:
$$\pi(r,p)=r^{1/2}p^{-1}(1-2)^{-1/2}.$$
Combining the likelihood and the prior distribtion yields the following posterior distribution:
$$p(r,p|X)=\Bigg\{\Bigg[\prod_{i=1}^n\frac{\Gamma(r+x_i)}{\Gamma(r)x_i!}\Bigg]p^{n\bar{X}}(1-p)^{nr}\Bigg\}\Bigg\{r^{1/2}p^{-1}(1-2)^{-1/2}\Bigg\}$$
From this posterior we obtain the full conditionals. First consider $p|r,X$:
$$p(p|r,X)\propto p^{n\bar{x}-1}(1-p)^{nr+1/2-1}$$
We recognize this as the kernel of a beta distribution, namely

$$p|r,X\sim\mathcal{B}eta(n\bar{X},nr+1/2).$$
Next consider $r|p,X$:
$$p(r|p,X)\propto\bigg[\prod_{i=1}^n\Gamma(r+x_i)\bigg]\Gamma(r)^{-n}(1-p)^{nr}r^{1/2}$$
This is not a recognized distribtion. So if we wish to make inferences on $r$ we must use a Metropolis algorithm to sample from it.

\subsection{Zero Inflated Poisson}
\label{ss:mZiPoisson}
The Zero Inflated Poisson (ZIP) model has two parameters. The parameter p is the probability of a structural zero, and $\lambda$ corresponds to the parameter in a typical Poisson model. For a single observation x, the probability density is:

\[
p(x|p, \lambda) = pI_{x=0}(x) + (1-p)\frac{e^{-\lambda}\lambda^x}{x!}
\]
 
 
\noindent We can write the likelihood as follows:
$$
L(p, \lambda|X) = \prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]
$$

\noindent Bayarri, Berger, and Datta (2008) suggest using the prior distribution $\pi(\lambda, p) \propto \frac{1}{\sqrt{\lambda}}I(0<p<1)$. This gives us the following posterior 

\[
\prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[(1-p)\frac{e^{-\lambda}\lambda^{x_i - 1/2}}{x_i!}\bigg]
\]

\noindent Neither of the full conditional distributions is recognizable (see \ref{a:dZIP}). We can use a Metropolis-Hastings algorithm to sample from both of them. We will use a beta distribution as a proposal for p, and a gamma for $\lambda$. We will tune them to obtain a better acceptance rate. 


\subsection{Zero Inflated Negative Binomial}
\label{ss:mZiNBinom}
The Zero Inflated Negative Binomial (ZINB) model has three parameters $\sigma,$ the probability of a structural zero, and $p,r$ the usual negative binomial parameters. 
For a single $X$ the probability density is: 
$$p(X|\sigma, p, r) = \sigma I_{X=0}(X) + (1-\sigma)\frac{\Gamma(r+X)}{\Gamma(r)X!}.$$
We take the uniform priors for $\sigma$ and $p$ as well as the non-informative gamma for $r$ which is $r^{-1/2}$. For a full derivation, see \ref{a:dZINB}. My posterior is:
$$p(r,\sigma, p|X)\propto\left(\sigma + (1-\sigma)(1-p)^r\right)^Z(1-\sigma)^{N-Z}(1-p)^{(N-Z)r}p^{\sum_{i=1}^NX_i}r^{-1/2}\prod_{i=1}^N\left(\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)$$
This distribution does not factor nicely, so I will use the Metropolis algorithm to sample from it. 
Because this posterior does not suggest any obvious proposal distributions I will sample each independently from a normal distribution centered at $\theta^*$, and with a variance that is tuned to yeild an appropriate acceptance rate.

\section{Results}
\label{s:results}
\subsection{Poisson}
\label{ss:rPoisson}

\subsection{Negative Binomial}
\label{ss:rNBinom}

\subsection{Zero Inflated Poisson}
\label{ss:rZiPoisson}

In tuning the parameters of the two models, slightly different values were chosen for the two different event types. The proposal distribution selected for $\lambda$ was a gamma(2, 2) for tornados, and a gamma(1, 2) for flash floods. The proposal for p within the tornado model was a beta(1940, 60), whereas it was a beta(2945, 55) in the flash flood model. 

For each variable of interest, 20,000 samples were taken. As convergence was not immediately achieved, the first 10,000 samples were discarded as a burn-in. The results are summarized in Table~\ref{t:rZIP}.

\begin{table}
    \centering
    \caption{Results of taking 20,000 samples from the posterior distributions of $\lambda$ and p, compared between the two event types. The second column relays the mean of the sample for $\lambda$, with the 95 percent credible interval in parentheses. The third does the same for p. All means and credible intervals are taken after discarding the first 10,000 samples as a burn-in.}
    \label{t:rZIP}
    \begin{tabular}{| l | l | l |}
    \hline
    Event Type & $\lambda$ & p  \\ \hline
    $Tornado$ & 1.872 (1.030, 3.710) & 0.971 (0.968, 0.973) \\ \hline
    $Flash Flood$ & 0.562 (0.293, 0.972) & 0.982 (0.981, 0.983) \\ \hline
    \end{tabular}
\end{table}

\subsection{Zero Inflated Negative Binomial}
\label{ss:rZiNBinom}
<<zinbsampler, echo=FALSE>>=
@
<<densityplot, echo=FALSE>>=
@
<<zinbparams, echo=FALSE, cache=TRUE>>=
samplesize <- 1030000
burnin <- 30000
thin <- 100
r.var=.00002
p.var=.00001
sigma.var=.001
@
The ZINB model was fit using the Metropolis-Hastings algorithm with a multivariate truncated normal distribution used as the proposal distribution. For the source code of the sampler, please see \ref{a:cZINB}.

This model suffered severely from the curse of dimensionality. It was very slow to converge, and the very small variance (necessary to tune the acceptance rate) led to high autocorrelation, meaning agressive thinning was necessary. Autocorrelation and running mean plots the Flash Flood models can be found in Figure~\ref{f:zinbconvergence}. 
<<floodsample, cache=TRUE, cache.vars='flood.zinb', echo=FALSE, dependson='zinbparams'>>=
flood.zinb <- zinb.sampler(storm_details, "Flash Flood", samplesize, 
                           r.var=r.var, p.var=p.var, sigma.var=sigma.var, 
                           burnin=burnin, thinning=thin)
@
<<tornadosample, cache=TRUE, cache.vars='tornado.zinb', echo=FALSE, dependson='zinbparams'>>=
tornado.zinb <- zinb.sampler(storm_details, "Tornado", samplesize, 
                             r.var=r.var, p.var=p.var, sigma.var=sigma.var, 
                             burnin=burnin, thinning=thin)
@
In the end $\Sexpr{samplesize}$ samples were drawn originally for each model, with a burn in of $\Sexpr{burnin}$ and one of every $\Sexpr{thin}$ samples was retained, resulting in a final sample size of $\Sexpr{length(flood.zinb$sigma)}$. The flood model had an acceptance rate of $\Sexpr{mean(flood.zinb$ar)}$ and the tornado model had an acceptance rate of $\Sexpr{mean(flood.zinb$ar)}$. The resulting densities are pictured in Figure~\ref{f:zinbdensity}, and Table~\ref{t:ZINBparams}, though due to autocorrelation and questions of convergence the results should viewed with caution.
<<evaluation, echo=FALSE, cache=FALSE>>=
@
<<model-eval, echo=FALSE, cache=TRUE, dependson=c('floodsample', 'tornadosample')>>=
flood.dic.zinb <- dic(storm_details, "Flash Flood", flood.zinb$sigma, 
                      flood.zinb$r, flood.zinb$p)
tornado.dic.zinb <- dic(storm_details, "Tornado", tornado.zinb$sigma, 
                        tornado.zinb$r, tornado.zinb$p)
#flood.wiac.zinb <- wiac(storm_details, "Flash Flood", flood.zinb$sigma, 
#                   flood.zinb$r, flood.zinb$p)
#tornado.wiac.zinb <- wiac(storm_details, "Tornado", tornado.zinb$sigma, 
#                          tornado.zinb$r, tornado.zinb$p)
@

The DIC for floods and tornadoes respectively were $\Sexpr{as.integer(flood.dic.zinb)}$ and $\Sexpr{as.integer(tornado.dic.zinb)}$. I was unable to calculate WIACs because it was too computationally expensive.
\begin{table}
\centering
\caption{The following table shows the results of the flash flood ZINB model and the tornado ZINB model. It shows the mean and the median for each parameter as well as the 95\% credible interval.}
\label{t:ZINBparams}
\begin{tabular}{lcccccc}
\toprule
&\multicolumn{3}{c}{Flash Flood}&\multicolumn{3}{c}{Tornado}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
Parameter & Mean Value &Median Value & (95\% CI)& Mean Value &Median Value & (95\% CI)\\
\midrule
$\sigma$ & \Sexpr{mean(flood.zinb$sigma)} &
  \Sexpr{median(flood.zinb$sigma)}&
  (\Sexpr{quantile(flood.zinb$sigma, probs=c(.025))[1]}, 
    \Sexpr{quantile(flood.zinb$sigma, probs=c(.975))[1]})&
  \Sexpr{mean(tornado.zinb$sigma)} &
  \Sexpr{median(tornado.zinb$sigma)}&
  (\Sexpr{quantile(tornado.zinb$sigma, probs=c(.025))[1]}, 
    \Sexpr{quantile(tornado.zinb$sigma, probs=c(.975))[1]})\\
$p$ &  \Sexpr{mean(flood.zinb$p)} &
  \Sexpr{median(flood.zinb$p)}&
  (\Sexpr{quantile(flood.zinb$p, probs=c(.025))[1]}, 
    \Sexpr{quantile(flood.zinb$p, probs=c(.975))[1]})&
  \Sexpr{mean(tornado.zinb$p)} &
  \Sexpr{median(tornado.zinb$p)}&
  (\Sexpr{quantile(tornado.zinb$p, probs=c(.025))[1]}, 
    \Sexpr{quantile(tornado.zinb$p, probs=c(.975))[1]})\\
$r$ &  \Sexpr{mean(flood.zinb$r)} &
  \Sexpr{median(flood.zinb$r)}&
  (\Sexpr{quantile(flood.zinb$r, probs=c(.025))[1]}, 
    \Sexpr{quantile(flood.zinb$r, probs=c(.975))[1]})&
  \Sexpr{mean(tornado.zinb$r)} &
  \Sexpr{median(tornado.zinb$r)}&
  (\Sexpr{quantile(tornado.zinb$r, probs=c(.025))[1]}, 
    \Sexpr{quantile(tornado.zinb$r, probs=c(.975))[1]})\\
\bottomrule
\end{tabular}
\end{table}
\begin{figure}
	\centering
<<floodconvergence, cache=TRUE, echo=FALSE, dependson=c('floodsample', 'tornadosample'), fig.height=3.5>>=
B<-length(flood.zinb$sigma)
Bt<-length(tornado.zinb$sigma)
par(mfrow=c(2, 3))
par(mgp=c(1.25,.5,0))
par(mar=c(3.1,4.1,2.5,.1))
plot(cumsum(flood.zinb$sigma)/1:B, 
     main = expression(paste('Cum. Mean (Flood) ',sigma)),
     ylab = 'Cumulative Mean',
     type='l')
plot(cumsum(flood.zinb$r)/1:B, 
     main = expression(paste('Cum. Mean (Flood) ',r)),
     ylab = 'Cumulative Mean',
     type='l')
plot(cumsum(flood.zinb$p)/1:B, 
     type='l', 
     main = expression(paste('Cum. Mean (Flood) ',p)),
     ylab = 'Cumulative Mean')
acf(flood.zinb$sigma, 
    main = expression(paste('ACF (Flood) ',sigma)))
acf(flood.zinb$r,
    main = expression(paste('ACF (Flood) ',r)))
acf(flood.zinb$p,
    main = expression(paste('ACF (Flood) ',p)))
# plot(cumsum(tornado.zinb$sigma)/1:Bt, 
#      main = expression(paste('Cum. Mean (Tornado) ',sigma)),
#      ylab = 'Cumulative Mean',
#      type='l')
# plot(cumsum(tornado.zinb$r)/1:Bt, 
#      main = expression(paste('Cum. Mean (Tornado) ',r)),
#      ylab = 'Cumulative Mean',
#      type='l')
# plot(cumsum(tornado.zinb$p)/1:Bt, 
#      type='l', 
#      main = expression(paste('Cum. Mean (Tornado) ',p)),
#      ylab = 'Cumulative Mean')
# acf(tornado.zinb$sigma, 
#     main = expression(paste('ACF (Tornado) ',sigma)))
# acf(tornado.zinb$r,
#     main = expression(paste('ACF (Tornado) ',r)))
# acf(tornado.zinb$p,
#     main = expression(paste('ACF (Tornado) ',p)))
@
	\caption{Autocorrelation plots, and cumulative mean plots for each of the three parameters in the ZINB model fit on flash flood data. The tornado plots are not pictured, but are similar in character.}
	\label{f:zinbconvergence}
\end{figure} 

\begin{figure}
	\centering
<<zinbdensity, cache=TRUE, echo=FALSE, dependson=c('floodsample', 'tornadosample'), fig.height=3>>=
par(mfrow=c(1,3))
double.density.plot(flood.zinb$sigma, tornado.zinb$sigma,
                    expression(paste(sigma, ' Posterior Density ')), 
                    expression(sigma), 
                    expression(p*group("(",paste(sigma, "|", X),")")),
                    col=c('blue', 'black'))
double.density.plot(flood.zinb$p, tornado.zinb$p,
                    expression(paste(p, ' Posterior Density ')), 
                    expression(p), 
                    expression(p*group("(",paste(p, "|", X),")")),
                    col=c('blue', 'black'))
double.density.plot(flood.zinb$r, tornado.zinb$r,
                    expression(paste(r, ' Posterior Density ')), 
                    expression(r), 
                    expression(p*group("(",paste(r, "|", X),")")),
                    col=c('blue', 'black'))
@
	\caption{Posterior density curves for each of the three variables. The flood posterior is shown in blue and the tornado posterior is shown in black.}
	\label{f:zinbdensity}
\end{figure} 
\section{Discussion}
\label{s:discussion}
The goal of this analysis was to determine which of the four models was the best fit for the data. In order to make this determination the DIC and WAIC was calculated for each model on both tornados and flash floods. The results are summarized in Table~\ref{t:evalresults}.

\begin{table}
\centering
\caption{The following table shows the resulting DIC and WAIC for each of the four models on both the tornado data and the flash flood data. In the case of the zero inflated negative binomial model, WAIC was too computationally expensive, so it was not calculated.}
\label{t:evalresults}
\begin{tabular}{lcccc}
\toprule
&\multicolumn{2}{c}{Flash Flood}&\multicolumn{2}{c}{Tornado}\\
\cmidrule(r){2-3}\cmidrule(l){4-5}
Model & DIC &WAIC & DIC &WAIC\\
\midrule
Poisson & P FLOOD DIC& P FLOOD WAIC &P TORNADO DIC&P TORNADO WAIC\\
Negative Binomial & NB FLOOD DIC& NB FLOOD WAIC &NB TORNADO DIC&NB TORNADO WAIC\\
ZIP & ZIP FLOOD DIC& ZIP FLOOD WAIC &ZIP TORNADO DIC&ZIP TORNADO WAIC\\
ZINB & \Sexpr{flood.dic.zinb}& -- &\Sexpr{tornado.dic.zinb}&--\\
\bottomrule
\end{tabular}
\end{table}

\begin{thebibliography}{2}
  \bibitem{dataset} NOAA's Severe Weather Data Inventory, 
    \url{https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/}. 
    Accessed April 2017.
  \bibitem{ZIP} Bayarri, M., Berger, J., Datta, G. (2008). Objective testing of Poisson versus inflated Poisson models. IMS 	Collections, 3, 105-121. 
\end{thebibliography}
\clearpage
\appendix
\section{Code}
\label{a:code}
This appendix includes the code used to implement the models.
\subsection{Zero Inflated Negative Binomial code}
\label{a:cZINB}
<<zinbsampler-source, echo=TRUE, ref.label='zinbsampler'>>=
@

\section{Derivations}
\label{a:derivation}
This appendix will include details on the calculations required to derive our models.
\subsection{Zero Inflated Poisson Derivation}
\label{a:dZIP}
\noindent In obtaining our full conditionals, we can simplify this slightly to obtain the following:

\[
p(\lambda|X, p) \propto \prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[e^{-\lambda}\lambda^{x_i - 1/2}\bigg]
\]

\[
p(p|X, \lambda) \propto \prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[(1-p)\bigg]
\]
\subsection{Zero Inflated Negative Binomial Derivation}
\label{a:dZINB}
The likelihood for the ZINB is 
\begin{align*}
\mathcal{L}(X|\sigma, p, r) &= \prod_{i=1}^N \sigma I_{X=0}(X_i) + (1-\sigma)\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\\
\intertext{For ease of notation let $Z$ be the number of zero values in $X$, and $N$ be the total number of observations.}
&=\prod_{X_i=0}\left(\sigma + (1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\right)\prod_{X_i\ne 0}\left((1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\right)\\
&=\left(\sigma + (1-\sigma)(1-p)^r\right)^Z\prod_{X_i\ne 0}\left((1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\right)\\
&\propto\left(\sigma + (1-\sigma)(1-p)^r\right)^Z\prod_{X_i\ne 0}\left((1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)\\
&\propto\left(\sigma + (1-\sigma)(1-p)^r\right)^Z(1-\sigma)^{N-Z}(1-p)^{(N-Z)r}p^{\sum_{i=1}^NX_i}\prod_{i=1}^n\left(\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)
\end{align*}
As mentioned in section \ref{ss:mZiNBinom} we take the uniform priors for $\sigma$ and $p$ as well as the non-informative gamma for $r$ which is $r^{-1/2}$. Therefore my joint posterior is:
\begin{align*}
p(r,\sigma, p|X)\propto&\left(\sigma + (1-\sigma)(1-p)^r\right)^Z(1-\sigma)^{N-Z}(1-p)^{(N-Z)r}p^{\sum_{i=1}^NX_i}r^{-1/2}\prod_{i=1}^N\left(\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)\\
\intertext{I am now going to take the log of the posterior because it helps with computation}
\ln\left(p(r,\sigma, p|X)\right)\propto&Z\ln\left(1 + (1/\sigma-1)(1-p)^r\right) + Z\ln(\sigma) + (N-Z)\ln(1-\sigma)+(N-Z)r\ln(1-p)\\
&+\sum_{i=1}^NX_i\ln(p)-\ln(r)/2-N\ln(\Gamma(r))+\sum_{i=1}^N\ln(\Gamma(r+X_i))
\end{align*}
\end{document}