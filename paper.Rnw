\documentclass{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx,float}
\usepackage{multirow,setspace}
\usepackage{enumerate}
\usepackage{booktabs}
\usepackage{placeins}
\usepackage{cite}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{hyperref}
\usepackage{listings}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\tab}{\hspace{0.5cm}}
\newcommand{\modref}[1]{(\ref{#1})}
\mathchardef\mhyphen="2D




\newcounter{DefnCounter}
\setcounter{DefnCounter}{1}

\newcounter{ThmCounter}
\setcounter{ThmCounter}{1}

\newcounter{ExampleCounter}
\setcounter{ExampleCounter}{1}

\newcommand{\defn}[1]{\textsc{Definition 1.\arabic{DefnCounter}\stepcounter{DefnCounter}: #1\\} }
\newcommand{\thm}{\textsc{Theorem 1.\arabic{ThmCounter}\stepcounter{ThmCounter}\\} }
\newcommand{\ex}{\textsc{Example 1.\arabic{ExampleCounter}\stepcounter{ExampleCounter}\\} }

\newcommand{\Defn}{\underline{Definition}}
\newcommand{\Q}{\underline{Question}}
\newcommand{\Qs}{\underline{Questions}}
\newcommand{\bbeta}{{\mbox{\boldmath$\beta$}}}
\newcommand{\bmu}{{\mbox{\boldmath$\mu$}}}
\newcommand{\balpha}{{\mbox{\boldmath$\alpha$}}}
\newcommand{\btheta}{{\mbox{\boldmath$\theta$}}}
\newcommand{\bphi}{{\mbox{\boldmath$\phi$}}}
\newcommand{\bSigma}{{\mbox{\boldmath$\Sigma$}}}
\newcommand{\bLambda}{{\mbox{\boldmath$\Lambda$}}}
\newcommand{\bpi}{{\mbox{\boldmath$\pi$}}}
\newcommand{\R}{\texttt{R}}
\newcommand{\Lik}{\mathcal{L}}
\newcommand{\bx}{\textbf{x}}
\newcommand{\by}{\textbf{y}}
\newcommand{\bX}{\textbf{X}}
\newcommand{\sic}{\text{Inv-}\chi^2}


\newcommand{\sao}{SaO$_2$}

\setlength{\marginparwidth}{2cm}
\begin{document}
<<imports, cache=FALSE, echo=FALSE>>= 
read_chunk('zinb_sampler.R')
options(scipen=4, digits=3)
library('truncnorm')
@
<<dataset, echo=FALSE, cache=FALSE>>= 
load('small_storms.RData')
storm_details <- small_storms
@
\begin{center}
	\vspace{0.1cm}
	\textsc{\LARGE MATH 640 Final Project} \\[0.1cm]
	Jason Michaels (jam521), Niko Paulson (ndp32), Miranda Seitz-McLeese (mgs85) 
\end{center}
\section{Introduction}
\label{s:intro}
This analysis will be done on a data set of a variety of measurements about severe weather in the United States. 
The data set contains a variety of measures from severe weather events in the United States from 1996-2016. It was taken from the NOAA website \cite{dataset}.
For this project we focused on the deaths directly attributable to the event.
Understanding how and at what rate severe weather events become lethal in the United States has tremendous public health impacts.
In this paper we compare four possible models for the deaths: The traditional Poisson and negative binomial distributions, as well as the zero inflated variant of each.

The remainder of this analysis is organized as follows: Section~\ref{s:methods} discusses and derives the models. Section~\ref{s:results} describes the results of the analysis. And Section~\ref{s:discussion} contains the conclusions.

\section{Methods}
\label{s:methods}
The deaths attributed to a severe weather event is `count' data. 
The most common model used for count data is the Poisson distribution. 
However for some weather events, the negative binomial model is a better fit, because the Poisson distribution assumes that the events being counted occur independently.

Fortunately, the vast majority of severe weather events in the United States involve no deaths, therefore we wanted to also account for the possibility of structural zeros, therefore we also considered zero inflated variants. 
These distributions are created by returning $0$ with probability $\sigma$ and sampling from the original distribution with probability $(1-\sigma)$. 

We will derive and fit a model for each of the four distributions and see if there is a difference in our results and evaluate to determine which model best fits the data.

\subsection{Poisson}
\label{ss:mPoisson}

\subsection{Negative Binomial}
\label{ss:mNBinom}


\subsection{Zero Inflated Poisson}
\label{ss:mZiPoisson}
The Zero Inflated Poisson (ZIP) model has two parameters. The parameter p is the probability of a structural zero, and $\lambda$ corresponds to the parameter in a typical Poisson model. For a single observation x, the probability density is:

\[
p(x|p, \lambda) = pI_{x=0}(x) + (1-p)\frac{e^{-\lambda}\lambda^x}{x!}
\]


\noindent We can write the likelihood as follows:
$$
L(p, \lambda|X) = \prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]
$$

\noindent Bayarri, Berger, and Datta (2008) \cite{ZIP} suggest using the prior distribution $\pi(\lambda, p) \propto \frac{1}{\sqrt{\lambda}}I(0<p<1)$. This gives us the following posterior 

\[
\prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[(1-p)\frac{e^{-\lambda}\lambda^{x_i - 1/2}}{x_i!}\bigg]
\]

\noindent In obtaining our full conditionals, we can simplify this slightly to obtain the following:

\[
p(\lambda|X, p) \propto \prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[e^{-\lambda}\lambda^{x_i - 1/2}\bigg]
\]

\[
p(p|X, \lambda) \propto \prod_{x_i=0}\bigg[p+(1-p)\frac{e^{-\lambda}\lambda^{x_i}}{x_i!}\bigg]\prod_{x_i \ne 0}\bigg[(1-p)\bigg]
\]

\noindent Neither of these distributions is recognizable. We can use a Metropolis-Hastings algorithm to sample from both of them. We will use a beta distribution as a proposal for p, and a gamma for $\lambda$. We will tune them to obtain a better acceptance rate. 

\subsection{Zero Inflated Negative Binomial}
\label{ss:mZiNBinom}
The Zero Inflated Negative Binomial (ZINB) model has three parameters $\sigma,$ the probability of a structural zero, and $p,r$ the usual negative binomial parameters. 
For a single $X$ the probability density is: 
$$p(X|\sigma, p, r) = \sigma I_{X=0}(X) + (1-\sigma)\frac{\Gamma(r+X)}{\Gamma(r)X!}.$$
We take the uniform priors for $\sigma$ and $p$ as well as the non-informative gamma for $r$ which is $r^{-1/2}$. For a full derivation, see \ref{a:dZINB}. My posterior is:
$$p(r,\sigma, p|X)\propto\left(\sigma + (1-\sigma)(1-p)^r\right)^Z(1-\sigma)^{N-Z}(1-p)^{(N-Z)r}p^{\sum_{i=1}^NX_i}r^{-1/2}\prod_{i=1}^N\left(\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)$$
This distribution does not factor nicely, so I will use the Metropolis algorithm to sample from it. 
Because this posterior does not suggest any obvious proposal distributions I will sample each independently from a normal distribution centered at $\theta^*$, and with a variance that is tuned to yeild an appropriate acceptance rate.

\section{Results}
\label{s:results}
\subsection{Poisson}
\label{ss:rPoisson}

\subsection{Negative Binomial}
\label{ss:rNBinom}

\subsection{Zero Inflated Poisson}
\label{ss:rZiPoisson}

\subsection{Zero Inflated Negative Binomial}
\label{ss:rZiNBinom}
<<zinbsampler, echo=FALSE>>=
@
<<densityplot, echo=FALSE>>=
@
<<zinbparams, echo=FALSE, cache=TRUE>>=
samplesize <- 650000
burnin <- 20000
thin <- 70
r.var=.00002
p.var=.00001
sigma.var=.001
@
The ZINB model was fit using the Metropolis-Hastings algorithm with a multivariate truncated normal distribution used as the proposal distribution. For the source code of the sampler, please see \ref{a:cZINB}.

This model suffered severely from the curse of dimensionality. It was very slow to converge, and the very small variance (necessary to tune the acceptance rate) led to high autocorrelation, meaning agressive thinning was necessary. Autocorrelation and running mean plots for both the Tornado and the Flash Flood models can be found in Figure~\ref{f:zinbconvergence}. 
<<floodsample, cache=TRUE, cache.vars='flood.zinb', echo=FALSE, dependson='zinbparams'>>=
flood.zinb <- zinb.sampler(storm_details, "Flash Flood", samplesize, 
                           r.var=r.var, p.var=p.var, sigma.var=sigma.var, 
                           burnin=burnin, thinning=thin)
@
<<tornadosample, cache=TRUE, cache.vars='tornado.zinb', echo=FALSE, dependson='zinbparams'>>=
tornado.zinb <- zinb.sampler(storm_details, "Tornado", samplesize, 
                             r.var=r.var, p.var=p.var, sigma.var=sigma.var, 
                             burnin=burnin, thinning=thin)
@
In the end $\Sexpr{samplesize}$ samples were drawn originally for each model, with a burn in of $\Sexpr{burnin}$ and one of every $\Sexpr{thin}$ samples was retained, resulting in a final sample size of $\Sexpr{length(flood.zinb$sigma)}$. The flood model had an acceptance rate of $\Sexpr{mean(flood.zinb$ar)}$ and the tornado model had an acceptance rate of $\Sexpr{mean(flood.zinb$ar)}$. The resulting densities are pictured in Figure~\ref{f:zinbdensity}, and Table~\ref{t:ZINBparams}, though due to autocorrelation and questions of convergence the results should viewed with caution.
<<evaluation, echo=FALSE, cache=FALSE>>=
@
<<model-eval, echo=FALSE, cache=TRUE, dependson=c('floodsample', 'tornadosample')>>=
flood.dic.zinb <- dic(storm_details, "Flash Flood", flood.zinb$sigma, 
                      flood.zinb$r, flood.zinb$p)
tornado.dic.zinb <- dic(storm_details, "Tornado", tornado.zinb$sigma, 
                        tornado.zinb$r, tornado.zinb$p)
#flood.wiac.zinb <- wiac(storm_details, "Flash Flood", flood.zinb$sigma, 
#                   flood.zinb$r, flood.zinb$p)
#tornado.wiac.zinb <- wiac(storm_details, "Tornado", tornado.zinb$sigma, 
#                          tornado.zinb$r, tornado.zinb$p)
@

The DIC for floods and tornadoes respectively were $\Sexpr{as.integer(flood.dic.zinb)}$ and $\Sexpr{as.integer(tornado.dic.zinb)}$. I was unable to calculate WIACs because it was too computationally expensive.
\begin{table}
\centering
\caption{The following table shows the results of the flash flood ZINB model and the tornado ZINB model. It shows the mean and the median for each parameter as well as the 95\% credible interval.}
\label{t:ZINBparams}
\begin{tabular}{lcccccc}
\toprule
&\multicolumn{3}{c}{Flash Flood}&\multicolumn{3}{c}{Tornado}\\
\cmidrule(r){2-4}\cmidrule(l){5-7}
Parameter & Mean Value &Median Value & (95\% CI)& Mean Value &Median Value & (95\% CI)\\
\midrule
$\sigma$ & \Sexpr{mean(flood.zinb$sigma)} &
  \Sexpr{median(flood.zinb$sigma)}&
  (\Sexpr{quantile(flood.zinb$sigma, probs=c(.025))[1]}, 
    \Sexpr{quantile(flood.zinb$sigma, probs=c(.975))[1]})&
  \Sexpr{mean(tornado.zinb$sigma)} &
  \Sexpr{median(tornado.zinb$sigma)}&
  (\Sexpr{quantile(tornado.zinb$sigma, probs=c(.025))[1]}, 
    \Sexpr{quantile(tornado.zinb$sigma, probs=c(.975))[1]})\\
$p$ &  \Sexpr{mean(flood.zinb$p)} &
  \Sexpr{median(flood.zinb$p)}&
  (\Sexpr{quantile(flood.zinb$p, probs=c(.025))[1]}, 
    \Sexpr{quantile(flood.zinb$p, probs=c(.975))[1]})&
  \Sexpr{mean(tornado.zinb$p)} &
  \Sexpr{median(tornado.zinb$p)}&
  (\Sexpr{quantile(tornado.zinb$p, probs=c(.025))[1]}, 
    \Sexpr{quantile(tornado.zinb$p, probs=c(.975))[1]})\\
$r$ &  \Sexpr{mean(flood.zinb$r)} &
  \Sexpr{median(flood.zinb$r)}&
  (\Sexpr{quantile(flood.zinb$r, probs=c(.025))[1]}, 
    \Sexpr{quantile(flood.zinb$r, probs=c(.975))[1]})&
  \Sexpr{mean(tornado.zinb$r)} &
  \Sexpr{median(tornado.zinb$r)}&
  (\Sexpr{quantile(tornado.zinb$r, probs=c(.025))[1]}, 
    \Sexpr{quantile(tornado.zinb$r, probs=c(.975))[1]})\\
\bottomrule
\end{tabular}
\end{table}
\begin{figure}
	\centering
<<floodconvergence, cache=TRUE, echo=FALSE, dependson=c('floodsample', 'tornadosample'), fig.height=4.75, fig.width=7>>=
B<-length(flood.zinb$sigma)
Bt<-length(tornado.zinb$sigma)
par(mfrow=c(4, 3))
par(mgp=c(1.25,.5,0))
par(mar=c(3.1,4.1,2.5,.1))
plot(cumsum(flood.zinb$sigma)/1:B, 
     main = expression(paste('Cum. Mean (Flood) ',sigma)),
     ylab = 'Cumulative Mean',
     type='l')
plot(cumsum(flood.zinb$r)/1:B, 
     main = expression(paste('Cum. Mean (Flood) ',r)),
     ylab = 'Cumulative Mean',
     type='l')
plot(cumsum(flood.zinb$p)/1:B, 
     type='l', 
     main = expression(paste('Cum. Mean (Flood) ',p)),
     ylab = 'Cumulative Mean')
acf(flood.zinb$sigma, 
    main = expression(paste('ACF (Flood) ',sigma)))
acf(flood.zinb$r,
    main = expression(paste('ACF (Flood) ',r)))
acf(flood.zinb$p,
    main = expression(paste('ACF (Flood) ',p)))
plot(cumsum(tornado.zinb$sigma)/1:Bt, 
     main = expression(paste('Cum. Mean (Tornado) ',sigma)),
     ylab = 'Cumulative Mean',
     type='l')
plot(cumsum(tornado.zinb$r)/1:Bt, 
     main = expression(paste('Cum. Mean (Tornado) ',r)),
     ylab = 'Cumulative Mean',
     type='l')
plot(cumsum(tornado.zinb$p)/1:Bt, 
     type='l', 
     main = expression(paste('Cum. Mean (Tornado) ',p)),
     ylab = 'Cumulative Mean')
acf(tornado.zinb$sigma, 
    main = expression(paste('ACF (Tornado) ',sigma)))
acf(tornado.zinb$r,
    main = expression(paste('ACF (Tornado) ',r)))
acf(tornado.zinb$p,
    main = expression(paste('ACF (Tornado) ',p)))
@
	\caption{Autocorrelation plots, index plots, and cumulative mean plots for each of the three parameters in the ZINB model fit on flash flood and the tornado data.}
	\label{f:zinbconvergence}
\end{figure} 

\begin{figure}
	\centering
<<zinbdensity, cache=TRUE, echo=FALSE, dependson=c('floodsample', 'tornadosample'), fig.height=3>>=
par(mfrow=c(1,3))
double.density.plot(flood.zinb$sigma, tornado.zinb$sigma,
                    expression(paste(sigma, ' Posterior Density ')), 
                    expression(sigma), 
                    expression(p*group("(",paste(sigma, "|", X),")")),
                    col=c('blue', 'black'))
double.density.plot(flood.zinb$p, tornado.zinb$p,
                    expression(paste(p, ' Posterior Density ')), 
                    expression(p), 
                    expression(p*group("(",paste(p, "|", X),")")),
                    col=c('blue', 'black'))
double.density.plot(flood.zinb$r, tornado.zinb$r,
                    expression(paste(r, ' Posterior Density ')), 
                    expression(r), 
                    expression(p*group("(",paste(r, "|", X),")")),
                    col=c('blue', 'black'))
@
	\caption{Posterior density curves for each of the three variables. The flood posterior is shown in blue and the tornado posterior is shown in black.}
	\label{f:zinbdensity}
\end{figure} 
\section{Discussion}
\label{s:discussion}

\begin{thebibliography}{2}
  \bibitem{dataset} NOAA's Severe Weather Data Inventory, 
    \url{https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/}. 
    Accessed April 2017.
  \bibitem{ZIP} Bayarri, M., Berger, J., Datta, G. (2008). Objective testing of Poisson versus inflated Poisson models. IMS 	Collections, 3, 105-121. 
\end{thebibliography}
\clearpage
\appendix
\section{Code}
\label{a:code}
This appendix includes the code used to implement the models.
\subsection{Zero Inflated Negative Binomial code}
\label{a:cZINB}
<<zinbsampler-source, echo=TRUE, ref.label='zinbsampler'>>=
@

\section{Derivations}
\label{a:derivation}
This appendix will include details on the calculations required to derive our models.
\subsection{Zero Inflated Negative Binomial Derivation}
\label{a:dZINB}
The likelihood for the ZINB is 
\begin{align*}
\mathcal{L}(X|\sigma, p, r) &= \prod_{i=1}^N \sigma I_{X=0}(X_i) + (1-\sigma)\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\\
\intertext{For ease of notation let $Z$ be the number of zero values in $X$, and $N$ be the total number of observations.}
&=\prod_{X_i=0}\left(\sigma + (1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\right)\prod_{X_i\ne 0}\left((1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\right)\\
&=\left(\sigma + (1-\sigma)(1-p)^r\right)^Z\prod_{X_i\ne 0}\left((1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)X_i!}\right)\\
&\propto\left(\sigma + (1-\sigma)(1-p)^r\right)^Z\prod_{X_i\ne 0}\left((1-\sigma)p^{X_i}(1-p)^r\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)\\
&\propto\left(\sigma + (1-\sigma)(1-p)^r\right)^Z(1-\sigma)^{N-Z}(1-p)^{(N-Z)r}p^{\sum_{i=1}^NX_i}\prod_{i=1}^n\left(\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)
\end{align*}
As mentioned in section \ref{ss:mZiNBinom} we take the uniform priors for $\sigma$ and $p$ as well as the non-informative gamma for $r$ which is $r^{-1/2}$. Therefore my joint posterior is:
\begin{align*}
p(r,\sigma, p|X)\propto&\left(\sigma + (1-\sigma)(1-p)^r\right)^Z(1-\sigma)^{N-Z}(1-p)^{(N-Z)r}p^{\sum_{i=1}^NX_i}r^{-1/2}\prod_{i=1}^N\left(\frac{\Gamma(r+X_i)}{\Gamma(r)}\right)\\
\intertext{I am now going to take the log of the posterior because it helps with computation}
\ln\left(p(r,\sigma, p|X)\right)\propto&Z\ln\left(1 + (1/\sigma-1)(1-p)^r\right) + Z\ln(\sigma) + (N-Z)\ln(1-\sigma)+(N-Z)r\ln(1-p)\\
&+\sum_{i=1}^NX_i\ln(p)-\ln(r)/2-N\ln(\Gamma(r))+\sum_{i=1}^N\ln(\Gamma(r+X_i))
\end{align*}
\end{document}